{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Назви стовпців:\n",
      "Index(['X', 'Y', 'elevation', 'acq_time', 'frp', 'acq_date', 'confidence',\n",
      "       'latitude', 'scan', 'instrument', 'time_sprea', 'type', 'slope',\n",
      "       'version', 'brightness', 'group_id', 'bright_t31', 'daynight', 'id',\n",
      "       'satellite', 'track', 'Map', 'longitude'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Шлях до файлу CSV\n",
    "file_path = r\"C:\\Users\\a0494\\Desktop\\New folder (3)\\Кластерізовані\\Пожежі 2-14 днів\\full data\\landcover_result.csv\"\n",
    "\n",
    "# Завантаження датасету\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Виведення назв стовпців\n",
    "print(\"Назви стовпців:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 18.967437676192965\n",
      "         Actual  Predicted\n",
      "2323   0.000000   1.674908\n",
      "18111  0.000000   6.233357\n",
      "10259  2.861962   3.311373\n",
      "15942  0.000000   4.981366\n",
      "13889  0.000000   2.042039\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Шлях до нового файлу CSV\n",
    "file_path = r\"C:\\Users\\a0494\\Desktop\\New folder (3)\\Кластерізовані\\Пожежі 2-14 днів\\full data\\selected_fires_with_distance_final.csv\"\n",
    "\n",
    "# Завантаження датасету\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Вибір потрібних ознак і цільової змінної\n",
    "features = ['elevation', 'acq_time', 'frp', 'confidence', 'slope', 'brightness', 'bright_t31', 'Map']\n",
    "target = 'distance_to_nearest'\n",
    "\n",
    "# Виділення підмножини даних\n",
    "data = df[features + [target]].copy()\n",
    "\n",
    "# Розділення на тренувальний та тестовий набір\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Вибірки ознак та цільової змінної\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target].fillna(0)  # Заповнюємо NaN значення в цільовій змінній нулями\n",
    "\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[target].fillna(0)  # Заповнюємо NaN значення в цільовій змінній нулями\n",
    "\n",
    "# Обробка null значень\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Побудова моделі випадкового лісу\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Передбачення\n",
    "predictions = rf_model.predict(X_test_imputed)\n",
    "\n",
    "# Оцінка моделі\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Виведення результатів\n",
    "results = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "print(results.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 3.628971337774225\n",
      "Statistical Parameters for distance_to_nearest:\n",
      "Mean: 5.966562978508045\n",
      "Median: 2.59486144037297\n",
      "Standard Deviation: 6.34241750895222\n",
      "Variance: 40.22625985786368\n",
      "Minimum Value: 0.020532537759681\n",
      "Maximum Value: 19.997420317480373\n",
      "\n",
      "Statistical Parameters for Predictions:\n",
      "Mean: 6.122934682440525\n",
      "Median: 6.492246767518496\n",
      "Standard Deviation: 4.183676546070605\n",
      "Variance: 17.503149442141265\n",
      "Minimum Value: 0.3503962975259017\n",
      "Maximum Value: 16.412719172633853\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Шлях до нового файлу CSV\n",
    "file_path = r\"C:\\Users\\a0494\\Desktop\\New folder (3)\\Кластерізовані\\Пожежі 2-14 днів\\full data\\selected_fires_with_distance_final.csv\"\n",
    "\n",
    "# Завантаження датасету\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Вибір потрібних ознак і цільової змінної\n",
    "features = ['elevation', 'acq_time', 'frp', 'confidence', 'slope', 'brightness', 'bright_t31', 'Map']\n",
    "target = 'distance_to_nearest'\n",
    "\n",
    "# Вилучення рядків, де 'distance_to_nearest' містить NaN\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "# Розділення на тренувальний та тестовий набір\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Вибірки ознак та цільової змінної\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[target]\n",
    "\n",
    "# Обробка null значень\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Побудова моделі випадкового лісу\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Передбачення\n",
    "predictions = rf_model.predict(X_test_imputed)\n",
    "\n",
    "# Оцінка моделі\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Статистичні параметри цільової змінної\n",
    "print(f'Statistical Parameters for {target}:')\n",
    "print(f'Mean: {y_test.mean()}')\n",
    "print(f'Median: {y_test.median()}')\n",
    "print(f'Standard Deviation: {y_test.std()}')\n",
    "print(f'Variance: {y_test.var()}')\n",
    "print(f'Minimum Value: {y_test.min()}')\n",
    "print(f'Maximum Value: {y_test.max()}')\n",
    "\n",
    "# Статистичні параметри передбачень\n",
    "print(f'\\nStatistical Parameters for Predictions:')\n",
    "print(f'Mean: {predictions.mean()}')\n",
    "print(f'Median: {pd.Series(predictions).median()}')\n",
    "print(f'Standard Deviation: {pd.Series(predictions).std()}')\n",
    "print(f'Variance: {pd.Series(predictions).var()}')\n",
    "print(f'Minimum Value: {pd.Series(predictions).min()}')\n",
    "print(f'Maximum Value: {pd.Series(predictions).max()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Mean Absolute Error with Best Parameters: 3.6335435366924287\n",
      "          Actual  Predicted\n",
      "7717   13.918246  10.591405\n",
      "15402   1.271352  10.703757\n",
      "1805    4.119499   7.501541\n",
      "5553    1.283224   7.450547\n",
      "18816   0.898213   3.723566\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Шлях до нового файлу CSV\n",
    "file_path = r\"C:\\Users\\a0494\\Desktop\\New folder (3)\\Кластерізовані\\Пожежі 2-14 днів\\full data\\selected_fires_with_distance_final.csv\"\n",
    "\n",
    "# Завантаження датасету\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Вибір потрібних ознак і цільової змінної\n",
    "features = ['elevation', 'acq_time', 'frp', 'confidence', 'slope', 'brightness', 'bright_t31', 'Map']\n",
    "target = 'distance_to_nearest'\n",
    "\n",
    "# Вилучення рядків, де 'distance_to_nearest' містить NaN\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "# Розділення на тренувальний та тестовий набір\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Вибірки ознак та цільової змінної\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[target]\n",
    "\n",
    "# Обробка null значень\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Параметри для Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Побудова моделі Random Forest\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Отримання кращих параметрів\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Передбачення з кращими параметрами\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "predictions = best_rf_model.predict(X_test_imputed)\n",
    "\n",
    "# Оцінка моделі\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f'Mean Absolute Error with Best Parameters: {mae}')\n",
    "\n",
    "# Виведення результатів\n",
    "results = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "print(results.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error with Best Parameters: 3.6213004939723223\n",
      "          Actual  Predicted\n",
      "7717   13.918246  10.421731\n",
      "15402   1.271352  10.490225\n",
      "1805    4.119499   7.701637\n",
      "5553    1.283224   7.381803\n",
      "18816   0.898213   3.973178\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Шлях до нового файлу CSV\n",
    "file_path = r\"C:\\Users\\a0494\\Desktop\\New folder (3)\\Кластерізовані\\Пожежі 2-14 днів\\full data\\selected_fires_with_distance_final.csv\"\n",
    "\n",
    "# Завантаження датасету\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Вибір потрібних ознак і цільової змінної\n",
    "features = ['elevation', 'acq_time', 'frp', 'confidence', 'slope', 'brightness', 'bright_t31', 'Map']\n",
    "target = 'distance_to_nearest'\n",
    "\n",
    "# Вилучення рядків, де 'distance_to_nearest' містить NaN\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "# Розділення на тренувальний та тестовий набір\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Вибірки ознак та цільової змінної\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[target]\n",
    "\n",
    "# Обробка null значень\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Побудова та навчання моделі Random Forest з найкращими параметрами\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Передбачення\n",
    "predictions = rf_model.predict(X_test_imputed)\n",
    "\n",
    "# Оцінка моделі\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f'Mean Absolute Error with Best Parameters: {mae}')\n",
    "\n",
    "# Виведення результатів\n",
    "results = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "print(results.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 38\u001B[0m\n\u001B[0;32m     35\u001B[0m rf_model\u001B[38;5;241m.\u001B[39mfit(X_imputed, y)\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# Передбачення\u001B[39;00m\n\u001B[1;32m---> 38\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mrf_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_imputed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m# Додавання стовпця з передбаченнями до оригінального датасету\u001B[39;00m\n\u001B[0;32m     41\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPredicted_distance\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m predictions\n",
      "File \u001B[1;32m~\\PycharmProjects\\interp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:994\u001B[0m, in \u001B[0;36mForestRegressor.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    992\u001B[0m \u001B[38;5;66;03m# Parallel loop\u001B[39;00m\n\u001B[0;32m    993\u001B[0m lock \u001B[38;5;241m=\u001B[39m threading\u001B[38;5;241m.\u001B[39mLock()\n\u001B[1;32m--> 994\u001B[0m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequire\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msharedmem\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    995\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_accumulate_prediction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43my_hat\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlock\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    996\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43me\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimators_\u001B[49m\n\u001B[0;32m    997\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    999\u001B[0m y_hat \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_)\n\u001B[0;32m   1001\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y_hat\n",
      "File \u001B[1;32m~\\PycharmProjects\\interp\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     58\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     59\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     60\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     62\u001B[0m )\n\u001B[1;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\interp\\lib\\site-packages\\joblib\\parallel.py:1088\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1085\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1088\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1089\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1091\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1092\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[0;32m   1093\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[0;32m   1094\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\interp\\lib\\site-packages\\joblib\\parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\interp\\lib\\site-packages\\joblib\\parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32m~\\PycharmProjects\\interp\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32m~\\PycharmProjects\\interp\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\interp\\lib\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\PycharmProjects\\interp\\lib\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\PycharmProjects\\interp\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    121\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\interp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:650\u001B[0m, in \u001B[0;36m_accumulate_prediction\u001B[1;34m(predict, X, out, lock)\u001B[0m\n\u001B[0;32m    643\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_accumulate_prediction\u001B[39m(predict, X, out, lock):\n\u001B[0;32m    644\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    645\u001B[0m \u001B[38;5;124;03m    This is a utility function for joblib's Parallel.\u001B[39;00m\n\u001B[0;32m    646\u001B[0m \n\u001B[0;32m    647\u001B[0m \u001B[38;5;124;03m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001B[39;00m\n\u001B[0;32m    648\u001B[0m \u001B[38;5;124;03m    complains that it cannot pickle it when placed there.\u001B[39;00m\n\u001B[0;32m    649\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 650\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m \u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    651\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m lock:\n\u001B[0;32m    652\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\interp\\lib\\site-packages\\sklearn\\tree\\_classes.py:427\u001B[0m, in \u001B[0;36mBaseDecisionTree.predict\u001B[1;34m(self, X, check_input)\u001B[0m\n\u001B[0;32m    425\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    426\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_X_predict(X, check_input)\n\u001B[1;32m--> 427\u001B[0m proba \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    428\u001B[0m n_samples \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    430\u001B[0m \u001B[38;5;66;03m# Classification\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Шлях до нового файлу CSV\n",
    "file_path = r\"C:\\Users\\a0494\\Desktop\\New folder (3)\\Кластерізовані\\Пожежі 2-14 днів\\full data\\selected_fires_with_distance_final.csv\"\n",
    "\n",
    "# Завантаження датасету\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Вибір потрібних ознак і цільової змінної\n",
    "features = ['elevation', 'acq_time', 'frp', 'confidence', 'slope', 'brightness', 'bright_t31', 'Map']\n",
    "target = 'distance_to_nearest'\n",
    "\n",
    "# Вилучення рядків, де 'distance_to_nearest' містить NaN\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "# Вибірки ознак та цільової змінної\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Обробка null значень\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Побудова та навчання моделі Random Forest з найкращими параметрами\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_imputed, y)\n",
    "\n",
    "# Передбачення\n",
    "predictions = rf_model.predict(X_imputed)\n",
    "\n",
    "# Додавання стовпця з передбаченнями до оригінального датасету\n",
    "df['Predicted_distance'] = predictions\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Збереження результатів у новий CSV файл\n",
    "output_file_path = r\"C:\\Users\\a0494\\Desktop\\New folder (3)\\Кластерізовані\\Пожежі 2-14 днів\\full data\\selected_fires_with_distance_predictions.csv\"\n",
    "df.to_csv(output_file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\a0494\\Desktop\\New folder (3)\\Кластерізовані\\Пожежі 2-14 днів\\full data\\selected_fires_with_distance_predictions.csv\"\n",
    "# Завантаження датасету\n",
    "df = pd.read_csv(file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X          Y  elevation  acq_time   frp    acq_date  confidence  \\\n",
      "2944  3.8125  51.161902        8.0      1148  30.3  2020-07-31          45   \n",
      "\n",
      "      latitude  scan instrument  ...  daynight     id  satellite  track   Map  \\\n",
      "2944   51.1619   2.8      MODIS  ...         D  36170       Aqua    1.6  50.0   \n",
      "\n",
      "      longitude  nearest distance_to_nearest  Predicted_distance  \\\n",
      "2944     3.8125  36229.0            19.75635           12.618335   \n",
      "\n",
      "     Absolute_Error  \n",
      "2944       7.138015  \n",
      "\n",
      "[1 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Створення нового стовпця із значеннями абсолютної різниці між фактичною і передбаченою відстанню\n",
    "df['Absolute_Error'] = abs(df['distance_to_nearest'] - df['Predicted_distance'])\n",
    "\n",
    "# Виведення інформації про пожежі з великою похибкою\n",
    "large_errors = df[df['Absolute_Error'] > 7]\n",
    "print(large_errors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}